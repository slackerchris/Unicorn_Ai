# Quick Start Guide - Unicorn AI

## âœ… What's Working Now (Phase 1)

You can have **text conversations** with Luna, your AI companion!

### Start the Server

```bash
cd /home/chris/Documents/Git/Projects/Unicorn_Ai
venv/bin/python main.py
```

Server runs on: `http://localhost:8000`

### Method 1: Interactive Chat (Easiest)

```bash
cd /home/chris/Documents/Git/Projects/Unicorn_Ai
venv/bin/python test_chat.py
```

Then just type your messages!

### Method 2: Test with curl

```bash
# Send a message
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Hi Luna! How are you?"}'

# Check health
curl http://localhost:8000/health
```

### Method 3: View API Docs

Open in browser: `http://localhost:8000/docs`

---

## ğŸ¯ Current Features

- âœ… **Text conversations** - Natural, caring responses
- âœ… **Uncensored** - No content filters
- âœ… **Fast responses** - 2-4 seconds
- âœ… **Personality** - Luna is warm, caring, and fun
- âœ… **Private** - Everything runs locally

---

## ğŸ“Š Performance

- **Model**: dolphin-mistral (7B parameters)
- **VRAM Usage**: ~5-6GB
- **Response Time**: 2-4 seconds
- **GPU**: AMD RX 6700 XT (using ROCm)

---

## ğŸš€ Next Steps (Phase 2)

Add image generation so Luna can send you photos:

1. Install ComfyUI (you already have it in another project!)
2. Add IPAdapter for character consistency
3. Detect `[IMAGE: ...]` tags in responses
4. Generate images based on descriptions
5. Return images with text

**Estimated time**: 2-4 hours

---

## ğŸ› Troubleshooting

### Server won't start
```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# If not, start Ollama
sudo systemctl start ollama
```

### Slow responses
- Normal for first message (model loading)
- Subsequent messages should be fast

### Change personality
Edit `config/.env` and change:
```
PERSONA_NAME=Luna
PERSONA_DESCRIPTION=Your friendly, caring AI companion
```

---

## ğŸ“ Project Structure

```
Unicorn_Ai/
â”œâ”€â”€ main.py              # FastAPI backend
â”œâ”€â”€ test_chat.py         # Interactive chat script
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ config/
â”‚   â””â”€â”€ .env            # Configuration
â”œâ”€â”€ data/
â”‚   â””â”€â”€ .gitkeep        # (Future: database)
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ logs/           # Server logs
â””â”€â”€ venv/               # Python virtual environment
```

---

## ğŸ‰ You Did It!

You now have a working AI companion that:
- Talks naturally
- Has personality
- Is completely private
- Runs on your hardware
- Has no content filters

**Try it out and see how she responds!** ğŸ¦„
